{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fac6a96",
   "metadata": {},
   "source": [
    "# Comparing discoverability of Digital Commons and Figshare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82079309",
   "metadata": {},
   "source": [
    "## Background\n",
    "In this study, we compared the platform discoverability in terms of download counts of two hosted IR solutions, Digital Science and Figshare, using a randomized controlled experiment. We also explored the patterns related to the indexing of records in Google Scholar. \n",
    "\n",
    "This case study is conducted using the institutional repository and data repository of Singapore Management University (SMU), respectively hosted on Digital Commons (https://ink.library.smu.edu.sg/) and Figshare (https://researchdata.smu.edu.sg/).\n",
    "\n",
    "\n",
    "## Method\n",
    "\n",
    "### Hypothesis Development\n",
    "The main purpose of this study is to explore if there is any platform difference between Digital Commons and Figshare in attracting downloads to deposited academic publications. We experimented with two randomly selected groups of full text journal articles uploaded to both platforms around the same time. The usage and download statistics of both groups were tracked and monitored over 7 months. We work with the assumption that other factors affecting downloads such as quality of the article and popularity of research topics will be randomized among the two groups. Therefore, the difference in download counts can serve as a reasonable approximation of the platform discoverability difference between Digital Commons and Figshare. \n",
    "\n",
    "We established the following hypothesis: \n",
    "\n",
    "***H0: There is no difference in average paper downloads between Figshare and Digital Commons.***\n",
    "\n",
    "***H1: The average paper downloads differ between Figshare and Digital Commons.***\n",
    "\n",
    "The significance level is set to be 0.05.\n",
    "\n",
    "### Data Collection\n",
    "\n",
    "A total of 96 journal article records with full-text PDFs were exported from SMU's Current Research Information System (CRIS). Half of the records (48) were uploaded to InK, SMU’s IR hosted on Digital Commons, and the other half to SMU RDR on Figshare. \n",
    "\n",
    "The journal article metadata and full-text PDF were uploaded to both platforms towards the end of March 2021. Monthly download count statistics of each article from both platforms were collected from April to October 2021. \n",
    "During the course of the study, a few records were removed because of issues such as duplication or author request. The final dataset as of Dec 2021 contains 45 valid records from Digital Commons and 47 from Figshare. \n",
    "\n",
    "In addition to testing the proposed hypothesis, we were also interested in exploring how records from our repositories are indexed in Google Scholar. In late September, we did a round of checking and data collection about Google Scholar indexing and added 3 additional fields to the dataset. We searched for each article by title and checked on the following:\n",
    "\n",
    "1) Whether the record is indexed in Google Scholar at all\n",
    "\n",
    "2) If the record is in Google Scholar, whether our record is the only copy providing a unique PDF among the different versions of the same article\n",
    "\n",
    "3) Whether our record is shown as the primary record in Google Scholar\n",
    "\n",
    "The full dataset is available at https://doi.org/10.25440/smu.19121768. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5b759",
   "metadata": {},
   "source": [
    "## Analysis & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas\n",
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the csv data file\n",
    "df_data = pd.read_csv ('DCvsFigshare-downloads-combined-v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a8215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a preview of first 5 rows of the dataset\n",
    "print(df_data.head(5))\n",
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6a599",
   "metadata": {},
   "source": [
    "### Downloads comparison by platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary stats\n",
    "df_data[[\"IR\",\"Total\"]].groupby(\"IR\").describe()\n",
    "\n",
    "#check the mean df_data.groupby(\"IR\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa1792",
   "metadata": {},
   "source": [
    "In order to see whether there is a statistically significant difference between download counts of Figshare and Digital Commons, we conducted T-test to compare the mean downloads for items in the two repositories. \n",
    "\n",
    "<b>Null Hypothesis H0</b>: There is no difference for the average paper downloads of Figshare and Digital Commons. \n",
    "\n",
    "<b>Alternative Hypothesis H1</b>: The average paper downloads differ between Figshare and Digital Commons. \n",
    "\n",
    "The <b>significance level</b> is set to be 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d2fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#subsetting data\n",
    "dc = df_data.query('IR == \"InK\"')['Total']\n",
    "fig = df_data.query('IR == \"RDR\"')['Total']\n",
    "\n",
    "t_output = stats.ttest_ind (dc, fig, equal_var=False)\n",
    "display(t_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91382263",
   "metadata": {},
   "source": [
    "The p-value is calculated to be 0.596. Therefore the Null Hypothesis is accepted, and we conclude that the there is no statistically significant difference in the download counts between the two platforms. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704bb4d",
   "metadata": {},
   "source": [
    "### Additional analysis on Google Scholar availability\n",
    "\n",
    "Further exploratory analysis has been done to explore if there is any interesting patterns depending on whether and how records are indexed by Google Scholar. \n",
    "\n",
    "#### 1. Download counts comparison between records indexed and not indexed by Google Scholar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e8bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "#check whether sample is normally distributed using Shapiro-Wilk test \n",
    "#subsetting data for downloads between August to October (only include data after fixing GS indexing issue for Figshare)\n",
    "n_GS=df_data.query('GS_avail == 0')['AugToOct']\n",
    "y_GS=df_data.query('GS_avail == 1')['AugToOct']\n",
    "\n",
    "#perform t-test\n",
    "ttest_GS = stats.ttest_ind (y_GS, n_GS, equal_var=False)\n",
    "display(ttest_GS)\n",
    "#perform Mann–Whitney U test (non-parametric test) as the sample size for n_GS is considered small. \n",
    "utest_GS = stats.mannwhitneyu (y_GS, n_GS)\n",
    "display(utest_GS)\n",
    "#both shows that the difference in downloads not significant\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fceb97a6",
   "metadata": {},
   "source": [
    "From the results, it can be observed that there is no significant difference between downloads of records indexed by Google Scholar and that are not. \n",
    "[talk about the GS indexing issue and how it also supports the correlation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd561cfc",
   "metadata": {},
   "source": [
    "#### 2. Download counts comparison between records that provide unique PDF in Google Scholar (for records that are indexed by GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf11dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use t-test to compare as N>30\n",
    "#subsetting data\n",
    "n_uniq = df_data.query('uniq_PDF == 0')['Total']\n",
    "y_uniq = df_data.query('uniq_PDF == 1')['Total']\n",
    "\n",
    "df_data[[\"uniq_PDF\",\"Total\"]].groupby(\"uniq_PDF\").describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_uniq = stats.ttest_ind (y_uniq, n_uniq, equal_var=False)\n",
    "display(ttest_uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae59e41",
   "metadata": {},
   "source": [
    "\n",
    "#### 3. Will records that are the primary record on Google Scholar receive higher downloads compared to the ones that are not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_primary = df_data.query('primary == \"FALSE\"')['Total']\n",
    "y_primary = df_data.query('primary == \"TRUE\"')['Total']\n",
    "df_data[[\"primary\",\"Total\"]].groupby(\"primary\").describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e45313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use t-test to compare, N=22, still ok \n",
    "ttest_primary = stats.ttest_ind (y_primary, n_primary, equal_var=False)\n",
    "display(ttest_primary)\n",
    "#result is significant - primary records receive more downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform Mann–Whitney U test (non-parametric test) as the sample size for n_primary is considered small. \n",
    "utest_primary = stats.mannwhitneyu (y_primary, n_primary)\n",
    "display(utest_primary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7929e9f2",
   "metadata": {},
   "source": [
    "Both tests support that the difference between primary records and non-primary records are significant. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
